# FastSpeech2 è¯­éŸ³åˆæˆæ¨¡å‹

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.8.0-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

ä¸€ä¸ªä»é›¶å¼€å§‹å®ç°çš„ FastSpeech2 è¯­éŸ³åˆæˆæ¨¡å‹ï¼ŒåŸºäº PyTorch æ¡†æ¶ï¼Œç”¨äºå­¦ä¹ å’Œç ”ç©¶ç›®çš„ã€‚æœ¬é¡¹ç›®å®ç°äº†å®Œæ•´çš„ TTS æµæ°´çº¿ï¼ŒåŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ç”Ÿæˆã€‚

## ğŸš€ ç‰¹æ€§

- **å®Œæ•´çš„ FastSpeech2 å®ç°**ï¼šåŒ…å«ç¼–ç å™¨ã€è§£ç å™¨ã€é•¿åº¦è°ƒèŠ‚å™¨ç­‰æ ¸å¿ƒç»„ä»¶
- **ç«¯åˆ°ç«¯è®­ç»ƒæµç¨‹**ï¼šä»åŸå§‹éŸ³é¢‘åˆ°æœ€ç»ˆè¯­éŸ³åˆæˆçš„å®Œæ•´æµç¨‹
- **é«˜è´¨é‡å£°ç å™¨**ï¼šé›†æˆ HiFi-GAN å£°ç å™¨ï¼Œç”Ÿæˆé«˜è´¨é‡éŸ³é¢‘
- **çµæ´»çš„æ•°æ®å¤„ç†**ï¼šæ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼å’Œæ–‡æœ¬é¢„å¤„ç†
- **è¯¦ç»†çš„è®­ç»ƒç›‘æ§**ï¼šå®Œæ•´çš„è®­ç»ƒæ—¥å¿—å’Œå¯è§†åŒ–
- **æ˜“äºä½¿ç”¨çš„æ¨ç†æ¥å£**ï¼šç®€å•çš„æ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢
- **ğŸ¨ æ¨¡å‹å¯è§†åŒ–**ï¼šè‡ªåŠ¨ç”Ÿæˆæ¶æ„å›¾å’Œå±‚æ¬¡ç»“æ„å›¾
- **ğŸ“Š å‚æ•°ç»Ÿè®¡**ï¼šè¯¦ç»†çš„æ¨¡å‹å‚æ•°åˆ†æå’Œç»Ÿè®¡ä¿¡æ¯

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- PyTorch 2.8.0+
- CUDA 11.0+ (æ¨èä½¿ç”¨ GPU è®­ç»ƒ)
- è‡³å°‘ 8GB RAM
- è‡³å°‘ 10GB å¯ç”¨ç£ç›˜ç©ºé—´

## ğŸ› ï¸ å®‰è£…

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/aaasjp/scratch_models.git
cd stratch_models/train_model/audio/fastspeech2
```

### 2. åˆ›å»º Conda ç¯å¢ƒ

```bash
# åˆ›å»ºæ•°æ®é¢„å¤„ç†ç¯å¢ƒ
conda create -n aligner python=3.8
conda activate aligner
conda install -c conda-forge montreal-forced-aligner

# åˆ›å»ºè®­ç»ƒç¯å¢ƒ
conda create -n scratch-models python=3.8
conda activate scratch-models
```

### 3. å®‰è£…ä¾èµ–

```bash
# å®‰è£…è®­ç»ƒç¯å¢ƒä¾èµ–
conda activate scratch-models
pip install -r requirements_scratch-models.txt

# å®‰è£…æ•°æ®é¢„å¤„ç†ç¯å¢ƒä¾èµ–
conda activate aligner
pip install -r requirements_aligner.txt
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
fastspeech2/
â”œâ”€â”€ ğŸ“„ fastspeech2.py              # FastSpeech2 æ¨¡å‹å®šä¹‰
â”œâ”€â”€ ğŸ“„ fastspeech2_train.py        # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ ğŸ“„ fastspeech2_inference.py    # æ¨ç†è„šæœ¬
â”œâ”€â”€ ğŸ“„ fastspeech2_dataset.py      # æ•°æ®é›†å¤„ç†
â”œâ”€â”€ ğŸ“„ hifigan_vocoder.py          # HiFi-GAN å£°ç å™¨
â”œâ”€â”€ ğŸ“„ length_regulator.py         # é•¿åº¦è°ƒèŠ‚å™¨
â”œâ”€â”€ ğŸ“„ audio_to_mel_spectrogram.py # éŸ³é¢‘å¤„ç†å·¥å…·
â”œâ”€â”€ ğŸ“„ test_model_visualization.py # æ¨¡å‹å¯è§†åŒ–æµ‹è¯•è„šæœ¬
â”œâ”€â”€ ğŸ“ corpus/                     # åŸå§‹éŸ³é¢‘æ•°æ®
â”œâ”€â”€ ğŸ“ corpus_aligned/             # éŸ³ç´ å¯¹é½æ•°æ®
â”œâ”€â”€ ğŸ“ processed_data/             # å¤„ç†åçš„è®­ç»ƒæ•°æ®
â”œâ”€â”€ ğŸ“ checkpoints/                # æ¨¡å‹æ£€æŸ¥ç‚¹
â”œâ”€â”€ ğŸ“ outputs/                    # æ¨ç†è¾“å‡º
â”œâ”€â”€ ğŸ“ model_structure/            # æ¨¡å‹ç»“æ„å›¾
â”‚   â”œâ”€â”€ fastspeech2_architecture.png  # æ¶æ„å›¾
â”‚   â””â”€â”€ fastspeech2_hierarchy.png      # å±‚æ¬¡ç»“æ„å›¾
â”œâ”€â”€ ğŸ“ hifi_gan/                   # HiFi-GAN å£°ç å™¨å®ç°
â”œâ”€â”€ ğŸ“ test_files/                 # æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
â””â”€â”€ ğŸ“„ æ¨¡å‹è®­ç»ƒæ¨ç†æ“ä½œæ­¥éª¤è¯´æ˜.md  # è¯¦ç»†æ“ä½œæŒ‡å—
```
**æ³¨æ„ï¼šhifi_ganæ˜¯ä»https://github.com/jik876/hifi-gan.gitä¸‹è½½çš„ï¼Œå¹¶ä¸”æ”¹åŠ¨äº†ä»£ç ã€‚**

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æ•°æ®é¢„å¤„ç†

```bash
# æ¿€æ´»æ•°æ®é¢„å¤„ç†ç¯å¢ƒ
conda activate aligner

# ä¸‹è½½ MFA æ¨¡å‹å’Œè¯å…¸
mfa model download acoustic english_us_arpa
mfa model download dictionary english_us_arpa

# æ‰§è¡ŒéŸ³ç´ å¯¹é½
mfa align ./corpus english_us_arpa english_us_arpa ./corpus_aligned
```

### 2. æ„å»ºæ•°æ®é›†

```bash
# æ¿€æ´»è®­ç»ƒç¯å¢ƒ
conda activate scratch-models

# æ„å»ºè®­ç»ƒæ•°æ®é›†
python fastspeech2_dataset.py > dataset.log 2>&1
```

#### æ•°æ®å¤„ç†è¯¦è§£

æ•°æ®é›†æ„å»ºè¿‡ç¨‹åŒ…å«ä»¥ä¸‹å…³é”®æ­¥éª¤ï¼š

##### éŸ³é¢‘ç‰¹å¾æå–
- **æ¢…å°”é¢‘è°±å›¾**ï¼šä½¿ç”¨ librosa æå– 80 ç»´æ¢…å°”é¢‘è°±ç‰¹å¾
- **åŸºé¢‘ (Pitch)**ï¼šä½¿ç”¨ YIN ç®—æ³•æå–åŸºé¢‘ï¼ŒèŒƒå›´ 65.4Hz-2093Hz
- **èƒ½é‡ (Energy)**ï¼šä½¿ç”¨ RMS è®¡ç®—èƒ½é‡ï¼Œæ›´è´´è¿‘äººè€³æ„ŸçŸ¥

##### Pitch å¤„ç†æµç¨‹
1. **æå–é˜¶æ®µ**ï¼š
   - ä½¿ç”¨ `librosa.yin()` æå–åŸºé¢‘
   - è¿‡æ»¤æ— æ•ˆå€¼ï¼šè¶…å‡ºèŒƒå›´æˆ–æ¥è¿‘0çš„å€¼è®¾ä¸º0ï¼ˆè¡¨ç¤ºé™éŸ³ï¼‰
   - ä»…å¯¹æœ‰å£°æ®µè¿›è¡Œå¯¹æ•°è½¬æ¢ï¼š`f0[f0 > 0] = np.log(f0[f0 > 0] + 1)`

2. **å½’ä¸€åŒ–é˜¶æ®µ**ï¼š
   - åªå¯¹éé›¶å€¼è¿›è¡Œæ ‡å‡†åŒ–ï¼š`(x - mean) / std`
   - ä¿æŒé™éŸ³å¸§çš„0å€¼ä¸å˜
   - è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼šmin, max, mean, std

3. **é€†å½’ä¸€åŒ–é˜¶æ®µ**ï¼ˆæ¨ç†æ—¶ï¼‰ï¼š
   - å¯¹éé›¶å€¼è¿›è¡Œé€†æ ‡å‡†åŒ–ï¼š`x * std + mean`
   - è¶…å‡ºèŒƒå›´å¤„ç†ï¼š
     - å¦‚æœ < pitch_minï¼šè®¾ç½®ä¸º 0ï¼ˆé™éŸ³ï¼‰
     - å¦‚æœ > pitch_maxï¼šè®¾ç½®ä¸º pitch_maxï¼ˆä¸Šé™ï¼‰

##### Energy å¤„ç†æµç¨‹
1. **æå–é˜¶æ®µ**ï¼š
   - ä½¿ç”¨ `librosa.feature.rms()` è®¡ç®— RMS èƒ½é‡
   - è®¾ç½®èƒ½é‡é˜ˆå€¼ï¼šå°äºå…¨å±€æœ€å¤§å€¼1%è§†ä¸ºé™éŸ³
   - ä»…å¯¹æœ‰å£°æ®µè¿›è¡Œå¯¹æ•°è½¬æ¢ï¼š`energy[energy > 0] = np.log(energy[energy > 0] + 1)`

2. **å½’ä¸€åŒ–é˜¶æ®µ**ï¼š
   - åªå¯¹éé›¶å€¼è¿›è¡Œæ ‡å‡†åŒ–
   - ä¿æŒé™éŸ³å¸§çš„0å€¼ä¸å˜
   - è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼šmin, max, mean, std

3. **é€†å½’ä¸€åŒ–é˜¶æ®µ**ï¼ˆæ¨ç†æ—¶ï¼‰ï¼š
   - å¯¹éé›¶å€¼è¿›è¡Œé€†æ ‡å‡†åŒ–
   - è¶…å‡ºèŒƒå›´å¤„ç†ï¼š
     - å¦‚æœ < energy_minï¼šè®¾ç½®ä¸º 0ï¼ˆé™éŸ³ï¼‰
     - å¦‚æœ > energy_maxï¼šè®¾ç½®ä¸º energy_maxï¼ˆä¸Šé™ï¼‰

##### ç»Ÿè®¡ä¿¡æ¯ä¿å­˜
æ„å»ºè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆ `processed_data/stats.json`ï¼ŒåŒ…å«ï¼š
```json
{
  "pitch_min": 0.0,
  "pitch_max": 8.5,
  "pitch_mean": 4.2,
  "pitch_std": 1.8,
  "energy_min": 0.0,
  "energy_max": 6.1,
  "energy_mean": 2.3,
  "energy_std": 1.2,
  "duration_min": 0.1,
  "duration_max": 15.0,
  "duration_mean": 2.5,
  "duration_std": 1.8,
  "mel_min": -12.0,
  "mel_max": 2.0,
  "mel_mean": -5.2,
  "mel_std": 2.1
}
```

### 3. è®­ç»ƒæ¨¡å‹

```bash
# å¼€å§‹è®­ç»ƒ
python fastspeech2_train.py > train.log 2>&1

# ç›‘æ§è®­ç»ƒè¿›åº¦
tail -f train.log
```

### 4. æ¨¡å‹æ¨ç†

```bash
# å‡†å¤‡è¾“å…¥æ–‡æœ¬ï¼ˆå°å†™æ ¼å¼ï¼‰
echo "hello world" > input_texts.txt

# æ–‡æœ¬è½¬éŸ³ç´ 
conda activate aligner
mfa g2p input_texts.txt english_us_arpa output_phonemes.txt --num_pronunciations 1

# æ‰§è¡Œæ¨ç†
conda activate scratch-models
python fastspeech2_inference.py
```

ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶å°†ä¿å­˜åœ¨ `./outputs/output_from_phonemes.wav`ã€‚

### 5. æ¨¡å‹å¯è§†åŒ–

```bash
# ç”Ÿæˆæ¨¡å‹ç»“æ„å›¾
python test_model_visualization.py
```

è¿™å°†ç”Ÿæˆä»¥ä¸‹å¯è§†åŒ–æ–‡ä»¶ï¼š
- `./model_structure/fastspeech2_architecture.png` - æ¨¡å‹æ¶æ„å›¾
- `./model_structure/fastspeech2_hierarchy.png` - æ¨¡å‹å±‚æ¬¡ç»“æ„å›¾

## ğŸ“Š æ¨¡å‹æ¶æ„

### FastSpeech2 æ ¸å¿ƒç»„ä»¶

- **ç¼–ç å™¨ (Encoder)**ï¼šåŸºäº Transformer çš„æ–‡æœ¬ç¼–ç å™¨
- **é•¿åº¦è°ƒèŠ‚å™¨ (Length Regulator)**ï¼šå¯¹é½æ–‡æœ¬å’ŒéŸ³é¢‘é•¿åº¦
- **è§£ç å™¨ (Decoder)**ï¼šç”Ÿæˆæ¢…å°”é¢‘è°±å›¾
- **æ–¹å·®é€‚é…å™¨ (Variance Adaptor)**ï¼šé¢„æµ‹éŸ³è°ƒå’Œèƒ½é‡

#### æ•°æ®å¤„ç†æ ¸å¿ƒç‰¹æ€§

- **æ™ºèƒ½é™éŸ³å¤„ç†**ï¼šåŒºåˆ†æœ‰å£°æ®µå’Œé™éŸ³æ®µï¼Œåˆ†åˆ«å¤„ç†
- **å¯¹æ•°åŸŸè½¬æ¢**ï¼šå¯¹ pitch å’Œ energy è¿›è¡Œå¯¹æ•°è½¬æ¢ï¼Œç¬¦åˆäººè€³æ„ŸçŸ¥ç‰¹æ€§
- **ç»Ÿè®¡å½’ä¸€åŒ–**ï¼šåŸºäºè®­ç»ƒæ•°æ®ç»Ÿè®¡è¿›è¡Œæ ‡å‡†åŒ–ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
- **èŒƒå›´é™åˆ¶**ï¼šæ¨ç†æ—¶è‡ªåŠ¨é™åˆ¶è¾“å‡ºèŒƒå›´ï¼Œç¡®ä¿ç”Ÿæˆè´¨é‡
- **é›¶å€¼ä¿æŒ**ï¼šé™éŸ³å¸§ä¿æŒä¸º0ï¼Œé¿å…å¼•å…¥å™ªå£°

### å£°ç å™¨

- **HiFi-GAN**ï¼šé«˜è´¨é‡å£°ç å™¨ï¼Œå°†æ¢…å°”é¢‘è°±å›¾è½¬æ¢ä¸ºéŸ³é¢‘æ³¢å½¢

### ğŸ¨ æ¨¡å‹å¯è§†åŒ–

é¡¹ç›®æä¾›äº†è‡ªåŠ¨åŒ–çš„æ¨¡å‹ç»“æ„å¯è§†åŒ–åŠŸèƒ½ï¼š

#### æ¶æ„å›¾ (Architecture Diagram)
- æ¸…æ™°å±•ç¤ºæ•°æ®æµå‘
- æ˜¾ç¤ºå„ç»„ä»¶ä¹‹é—´çš„è¿æ¥å…³ç³»
- åŒ…å«ä¸­è‹±æ–‡åŒè¯­æ ‡ç­¾

#### å±‚æ¬¡ç»“æ„å›¾ (Hierarchy Diagram)
- è¯¦ç»†çš„æ¨¡å‹å±‚æ¬¡ç»“æ„
- å‚æ•°ç»Ÿè®¡ä¿¡æ¯
- ç»„ä»¶åŠŸèƒ½è¯´æ˜

#### ä½¿ç”¨æ–¹æ³•
```python
from fastspeech2 import FastSpeech2, print_model_info, visualize_model_structure

# åˆ›å»ºæ¨¡å‹
model = FastSpeech2(vocab_size=100, d_model=256)

# æ‰“å°æ¨¡å‹ä¿¡æ¯
print_model_info(model)

# ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡
visualize_model_structure(model, "./model_structure")
```

## ğŸ”§ é…ç½®é€‰é¡¹

### è®­ç»ƒå‚æ•°

```python
# åœ¨ fastspeech2_train.py ä¸­å¯è°ƒæ•´çš„å‚æ•°
parser.add_argument('--epochs', type=int, default=100)
parser.add_argument('--batch_size', type=int, default=16)
parser.add_argument('--learning_rate', type=float, default=0.0001)
parser.add_argument('--save_interval', type=int, default=10)
```

### æ¨¡å‹å‚æ•°

```python
# åœ¨ fastspeech2.py ä¸­çš„æ¨¡å‹é…ç½®
n_mel_channels=80,      # æ¢…å°”é¢‘è°±ç»´åº¦
n_phoneme_vocab=100,    # éŸ³ç´ è¯æ±‡è¡¨å¤§å°
encoder_dim=256,        # ç¼–ç å™¨ç»´åº¦
decoder_dim=256,        # è§£ç å™¨ç»´åº¦
```

### æ•°æ®å¤„ç†å‚æ•°

```python
# éŸ³é¢‘å¤„ç†å‚æ•°
sample_rate=22050,      # é‡‡æ ·ç‡
n_fft=1024,            # FFTçª—å£å¤§å°
hop_length=256,        # è·³è·ƒé•¿åº¦
win_length=1024,       # çª—å£é•¿åº¦
n_mels=80,             # æ¢…å°”é¢‘è°±ç»´åº¦

# Pitch æå–å‚æ•°
fmin=65.4,             # æœ€å°åŸºé¢‘ (C2)
fmax=2093.0,           # æœ€å¤§åŸºé¢‘ (C7)
energy_threshold=0.01, # èƒ½é‡é˜ˆå€¼ï¼ˆå…¨å±€æœ€å¤§å€¼çš„1%ï¼‰

# å½’ä¸€åŒ–å‚æ•°
eps=1e-6,              # æ•°å€¼ç¨³å®šæ€§å‚æ•°
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

- `train.log`ï¼šè®­ç»ƒæ—¥å¿—
- `logs/training_log.jsonl`ï¼šç»“æ„åŒ–è®­ç»ƒæ•°æ®
- `checkpoints/`ï¼šæ¨¡å‹æ£€æŸ¥ç‚¹
- `mel_output/`ï¼šæ¢…å°”é¢‘è°±å›¾å¯è§†åŒ–
- `model_structure/`ï¼šæ¨¡å‹ç»“æ„å›¾
  - `fastspeech2_architecture.png`ï¼šæ¶æ„å›¾
  - `fastspeech2_hierarchy.png`ï¼šå±‚æ¬¡ç»“æ„å›¾

## ğŸ¯ æ€§èƒ½æŒ‡æ ‡

- **è®­ç»ƒæ—¶é—´**ï¼šçº¦ 2-3 å°æ—¶ï¼ˆGPU è®­ç»ƒï¼‰
- **æ¨¡å‹å¤§å°**ï¼šçº¦ 50MB
- **æ¨ç†é€Ÿåº¦**ï¼šå®æ—¶ç”Ÿæˆï¼ˆ< 1ç§’ï¼‰
- **éŸ³é¢‘è´¨é‡**ï¼šé«˜ä¿çœŸåº¦è¯­éŸ³åˆæˆ

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **MFA å®‰è£…é—®é¢˜**
   ```bash
   # ç¡®ä¿ä½¿ç”¨ conda å®‰è£…
   conda install -c conda-forge montreal-forced-aligner
   ```

2. **CUDA å†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘æ‰¹æ¬¡å¤§å°
   python fastspeech2_train.py --batch_size 8
   ```

3. **éŸ³ç´ å¯¹é½å¤±è´¥**
   - æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ ¼å¼ï¼ˆæ¨è WAVï¼‰
   - ç¡®ä¿æ–‡æœ¬ä¸ºå°å†™
   - éªŒè¯ MFA æ¨¡å‹æ˜¯å¦æ­£ç¡®ä¸‹è½½

4. **æ¨¡å‹å¯è§†åŒ–é—®é¢˜**
   ```bash
   # ç¡®ä¿ matplotlib æ­£ç¡®å®‰è£…
   pip install matplotlib
   
   # å¦‚æœä¸­æ–‡å­—ä½“æ˜¾ç¤ºæœ‰é—®é¢˜
   python -c "import matplotlib.pyplot as plt; print(plt.rcParams['font.sans-serif'])"
   ```

5. **æ•°æ®å¤„ç†é—®é¢˜**
   ```bash
   # å¦‚æœ stats.json æ–‡ä»¶æŸåæˆ–ç¼ºå¤±
   rm -rf processed_data/
   python fastspeech2_dataset.py
   
   # å¦‚æœ pitch/energy æå–å¼‚å¸¸
   # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶è´¨é‡ï¼Œç¡®ä¿é‡‡æ ·ç‡æ­£ç¡®
   python -c "import librosa; print(librosa.get_samplerate('corpus/audio_000001.wav'))"
   
   # å¦‚æœå½’ä¸€åŒ–åæ•°å€¼å¼‚å¸¸
   # æ£€æŸ¥ stats.json ä¸­çš„ç»Ÿè®¡å€¼æ˜¯å¦åˆç†
   cat processed_data/stats.json
   ```

6. **æ¨ç†è´¨é‡é—®é¢˜**
   ```bash
   # å¦‚æœç”Ÿæˆçš„éŸ³é¢‘è´¨é‡å·®
   # æ£€æŸ¥ pitch_control å’Œ energy_control å‚æ•°
   python fastspeech2_inference.py --pitch_control 1.0 --energy_control 1.0
   
   # å¦‚æœå‡ºç°æ•°å€¼æº¢å‡º
   # æ£€æŸ¥é€†å½’ä¸€åŒ–åçš„æ•°å€¼èŒƒå›´
   python -c "
   import json
   with open('processed_data/stats.json', 'r') as f:
       stats = json.load(f)
   print('Pitch range:', stats['pitch_min'], 'to', stats['pitch_max'])
   print('Energy range:', stats['energy_min'], 'to', stats['energy_max'])
   "
   ```

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f train.log

# æŸ¥çœ‹æ•°æ®é›†æ„å»ºæ—¥å¿—
tail -f dataset.log
```

## ğŸ¨ æ¨¡å‹å¯è§†åŒ–ç¤ºä¾‹

### å¿«é€Ÿç”Ÿæˆæ¨¡å‹ç»“æ„å›¾

```bash
# è¿è¡Œå¯è§†åŒ–æµ‹è¯•è„šæœ¬
python test_model_visualization.py
```

### åœ¨ä»£ç ä¸­ä½¿ç”¨å¯è§†åŒ–åŠŸèƒ½

```python
import torch
from fastspeech2 import FastSpeech2, print_model_info, visualize_model_structure

# åˆ›å»ºæ¨¡å‹
model = FastSpeech2(
    vocab_size=100,
    d_model=256,
    n_layers=8,
    n_heads=2,
    d_ff=1024,
    n_mel_channels=80
)

# æ‰“å°è¯¦ç»†çš„æ¨¡å‹ä¿¡æ¯
print_model_info(model)

# ç”Ÿæˆæ¨¡å‹ç»“æ„å›¾
visualize_model_structure(model, "./my_model_structure")
```

### å¯è§†åŒ–è¾“å‡º

è¿è¡Œåä¼šç”Ÿæˆï¼š
- **æ¶æ„å›¾**ï¼šå±•ç¤ºæ•°æ®æµå‘å’Œç»„ä»¶è¿æ¥
- **å±‚æ¬¡ç»“æ„å›¾**ï¼šè¯¦ç»†çš„æ¨¡å‹å±‚æ¬¡å’Œå‚æ•°ç»Ÿè®¡
- **æ–‡æœ¬ä¿¡æ¯**ï¼šå®Œæ•´çš„æ¨¡å‹å‚æ•°åˆ†æ

## ğŸ“š å‚è€ƒèµ„æ–™

- [FastSpeech2 è®ºæ–‡](https://arxiv.org/abs/2006.04558)
- [HiFi-GAN è®ºæ–‡](https://arxiv.org/abs/2010.05646)
- [Montreal Forced Alignment](https://montreal-forced-aligner.readthedocs.io/en/v3.3.0/installation.html)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- æäº¤ GitHub Issue
- å‘é€é‚®ä»¶è‡³é¡¹ç›®ç»´æŠ¤è€…

---

**æ³¨æ„**ï¼šæœ¬é¡¹ç›®ä»…ç”¨äºå­¦ä¹ å’Œç ”ç©¶ç›®çš„ã€‚å•†ä¸šä½¿ç”¨è¯·ç¡®ä¿éµå®ˆç›¸å…³è®¸å¯è¯è¦æ±‚ã€‚
